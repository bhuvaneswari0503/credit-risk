{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8d5b1-f9fd-45c7-bdde-465c6781633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "shap_credit_risk_pipeline.py\n",
    "\n",
    "Requirements:\n",
    "pip install numpy pandas scikit-learn xgboost shap matplotlib joblib\n",
    "\n",
    "Place credit_risk_dataset.csv in the same directory as this script.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, classification_report\n",
    "from sklearn.calibration import calibration_curve\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "DATA_PATH = \"credit_risk_dataset.csv\"   # file created earlier\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# LOAD DATA\n",
    "# -------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.head())\n",
    "\n",
    "# -------------------------\n",
    "# PREPARE FEATURES / TARGET\n",
    "# -------------------------\n",
    "target_col = \"default\"\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found in dataset.\")\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Simple feature names list (all numeric in this synthetic dataset)\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# -------------------------\n",
    "# SPLIT\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)\n",
    "\n",
    "# -------------------------\n",
    "# BASE MODEL + HYPERPARAMETER TUNING (RandomizedSearch)\n",
    "# -------------------------\n",
    "base_clf = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 500],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0.0, 0.1, 0.5],\n",
    "    \"reg_lambda\": [1.0, 2.0, 5.0],\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Starting RandomizedSearchCV...\")\n",
    "rs.fit(X_train, y_train)\n",
    "print(\"Best params:\", rs.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", rs.best_score_)\n",
    "\n",
    "best_model = rs.best_estimator_\n",
    "\n",
    "# Save the trained model\n",
    "model_path = os.path.join(OUTPUT_DIR, \"xgb_best_model.joblib\")\n",
    "joblib.dump(best_model, model_path)\n",
    "print(\"Saved model to\", model_path)\n",
    "\n",
    "# -------------------------\n",
    "# PREDICTIONS & METRICS\n",
    "# -------------------------\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "print(\"\\nTest ROC-AUC: {:.4f}\".format(roc_auc))\n",
    "print(\"Test PR-AUC: {:.4f}\".format(pr_auc))\n",
    "print(\"\\nClassification report (threshold=0.5):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calibration curve\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(prob_pred, prob_true, marker='o', linewidth=2)\n",
    "plt.plot([0,1],[0,1], linestyle='--', label='Perfectly calibrated')\n",
    "plt.xlabel(\"Predicted probability\")\n",
    "plt.ylabel(\"Observed probability\")\n",
    "plt.title(\"Calibration curve\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"calibration_curve.png\"))\n",
    "plt.close()\n",
    "print(\"Saved calibration curve.\")\n",
    "\n",
    "# -------------------------\n",
    "# SHAP ANALYSIS\n",
    "# -------------------------\n",
    "# Use TreeExplainer for XGBoost\n",
    "explainer = shap.TreeExplainer(best_model, feature_perturbation=\"tree_path_dependent\")\n",
    "# compute shap values for test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# SUMMARY PLOT (dot)\n",
    "plt.figure(figsize=(8,6))\n",
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"shap_summary_dot.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved shap_summary_dot.png\")\n",
    "\n",
    "# FEATURE IMPORTANCE (bar)\n",
    "plt.figure(figsize=(8,6))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"shap_summary_bar.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"Saved shap_summary_bar.png\")\n",
    "\n",
    "# DEPENDENCE PLOT (choose top feature)\n",
    "# Identify top feature by mean(|SHAP|)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_idx = np.argmax(mean_abs_shap)\n",
    "top_feature = X_test.columns[top_idx]\n",
    "print(\"Top SHAP feature:\", top_feature)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "shap.dependence_plot(top_feature, shap_values, X_test, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_dependence_{top_feature}.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Saved shap_dependence_{top_feature}.png\")\n",
    "\n",
    "# FORCE PLOT for a single instance -> save as html\n",
    "shap.initjs()\n",
    "instance_idx = 0\n",
    "force_html = os.path.join(OUTPUT_DIR, f\"shap_force_instance_{instance_idx}.html\")\n",
    "force_plot = shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[instance_idx,:],\n",
    "    X_test.iloc[instance_idx,:],\n",
    "    matplotlib=False\n",
    ")\n",
    "shap.save_html(force_html, force_plot)\n",
    "print(f\"Saved SHAP force plot html: {force_html}\")\n",
    "\n",
    "# -------------------------\n",
    "# SAVE METRICS & FEATURE IMPORTANCE AS CSV\n",
    "# -------------------------\n",
    "metrics = {\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"pr_auc\": pr_auc,\n",
    "    \"best_params\": rs.best_params_,\n",
    "}\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(os.path.join(OUTPUT_DIR, \"metrics_summary.csv\"), index=False)\n",
    "\n",
    "# Save mean absolute shap per feature\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "feat_imp_df.to_csv(os.path.join(OUTPUT_DIR, \"shap_feature_importance.csv\"), index=False)\n",
    "\n",
    "print(\"Saved metrics and feature importance CSVs in\", OUTPUT_DIR)\n",
    "print(\"All done. Check the 'outputs' folder for plots, model, and CSVs.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
